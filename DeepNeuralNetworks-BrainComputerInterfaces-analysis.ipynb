{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep neural networks for analyzing recordings of Brain Computer Interfaces\n",
    "\n",
    "\n",
    "\n",
    "### Author:  Elsa Scola Martín and Enya Goñi Maganto\n",
    "\n",
    "### Objectives:\n",
    "\n",
    "- Apply deep neural networks for classifying BCI data.\n",
    "\n",
    "### What is done in the Notebook: \n",
    "\n",
    "- Load and preprocess the data\n",
    "    - Window method\n",
    "    - Adapt the label values\n",
    "    - Split the data\n",
    "- Classification with RNN - Tensorflow\n",
    "    - LSTM\n",
    "    - GRU\n",
    "- Classification with CNN - Keras\n",
    "- Analize and contrast the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we import all relevant libraries to be used in the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# General Imports\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "\n",
    "# RNN \n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from statistics import mean\n",
    "\n",
    "# CNN \n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# To load the data\n",
    "import scipy.io as sio\n",
    "from scipy import stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset, named \"Data set I: ‹motor imagery in ECoG recordings, session-to-session transfer›\" can be requested from http://www.bbci.de/competition/iii/#datasets. \n",
    "Introduce here http://www.bbci.de/competition/iii/#download a name and email and the credentials needed to download the dataset are sent to the email. Then, just download the Matlab file that corresponds to the dataset mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the data which is in matlab format, it takes less than a minute to load the data\n",
    "mat_contentsTest = sio.loadmat('Competition_test.mat')\n",
    "mat_contentsTrain = sio.loadmat('Competition_train.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'X'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We print the keys of the test dataset so we can see how is divided\n",
    "mat_contentsTest.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'X', 'Y'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We print the keys of the train dataset so we can see how is divided\n",
    "mat_contentsTrain.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloaded dataset consists of two parts, test data, which contains only the data with no labels so each team can submit their results, and train data with labels to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data X: (278, 64, 3000)\n",
      "Shape of train data Y: (278, 1)\n",
      "Shape of test data X: (100, 64, 3000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train data X: \"+ str(mat_contentsTrain['X'].shape))\n",
    "print(\"Shape of train data Y: \"+ str(mat_contentsTrain['Y'].shape))\n",
    "print(\"Shape of test data X: \"+ str(mat_contentsTest['X'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the train dataset had 2 parts:\n",
    "- Part 1: A 3D matrix containing the following information: 278 trials, where each one had the information that 64 electrode channels had gathered in parallel for 3 seconds, and 3000 samples of time series contained in each one of the 64 electrode channels.\n",
    "- Part 2: A vector of -1/1 values, that corresponded to the labels, one for each trial.\n",
    "\n",
    "The test dataset, on the other hand, had no labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that for each of the electrode channels there are 3000 samples, having a great size of samples can make it less manageable for the neural network to compute, is therefore recommended to reduce this size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of ECoG recordings (similarly for EEG recordings), we have to take into consideration that the signal is highly influenced not only by external sources of noise but also by the spatial characteristics of the data recording process. The electrodes positioned according to a standard 10-10 or 10-20 electrode placement system collect data which may be heavily distorted by the activity of the adjacent cortex areas—potentially irrelevant to the state of the user’s brain activity we want to classify.\n",
    "\n",
    "\n",
    "Thus, for ECoG and EEG data, our assumption is that reducing the number of samples produced by a single channel within a given time window can produce information that is more valuable and free of noise than if the signal is treated as a whole. \n",
    "To reduce the number of samples we compute the mean for each 100 samples, therefore the window size is 100, with an overlap of 50 samples, which means that for each 100 samples we take 50 from the previous set of 100 samples; we do this to convert time values into cross sectional attributes. Sliding time window methods are very useful in terms of fetching important patterns in the dataset that are highly dependent on the past bulk of observations.\n",
    "\n",
    "Moreover, using this technique we will obtain a reduced size of observations, this is specially convinient for us as Backpropagation Through Time can be computationally expensive when there is a high number of timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowing(sample):\n",
    "    # The first window ranges from 0 to 99, this values are going to be updated\n",
    "    i,j = 0,99\n",
    "    # In the \"sum\" variable we store the sum of the elements of each window\n",
    "    sum = 0\n",
    "    # In the \"means\" array we store the results of the mean of each window\n",
    "    means = []\n",
    "    l = 0\n",
    "    # In our case we have to compute 59 iterations as we have 3000 elements\n",
    "    for l in range(59):\n",
    "        for k in range(i,j):\n",
    "            sum += sample[k]\n",
    "        means.append(sum/100)\n",
    "        i += 50\n",
    "        j += 50\n",
    "        sum = 0\n",
    "    # This function returns a reduced number of samples for an electrode channel,\n",
    "    # we will compute this for each of the electrode channels\n",
    "    return means\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now reduce the number of samples for each of the electrode channels and create the matrices that represent our train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialize the matrix where the train data X will be stored\n",
    "trainData_X = np.zeros((278,64,59))\n",
    "\n",
    "# We loop for each sample of each electrode channel and insert the new reduced data on the tridimensional matrix \n",
    "for i in range (len(mat_contentsTrain['X'])):\n",
    "    for j in range (len(mat_contentsTrain['X'][i])):\n",
    "        trainData_X[i][j] = windowing(mat_contentsTrain['X'][i][j])\n",
    "\n",
    "# The labels of the training data stay the same\n",
    "trainData_Y = mat_contentsTrain['Y']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a reduced dataset of 278 x 64 x 59 instead of 278 x 64 x 3000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(278, 64, 59)\n",
      "(278, 1)\n"
     ]
    }
   ],
   "source": [
    "print(trainData_X.shape)\n",
    "print(trainData_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same for our test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialize the matrix where the test data X will be stored\n",
    "testData_X = np.zeros((100,64,59))\n",
    "\n",
    "# We loop for each sample of each electrode channel and insert the new reduced data on the tridimensional matrix \n",
    "for i in range (len(mat_contentsTest['X'])):\n",
    "    for j in range (len(mat_contentsTest['X'][i])):\n",
    "        testData_X[i][j] = windowing(mat_contentsTest['X'][i][j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 64, 59)\n"
     ]
    }
   ],
   "source": [
    "print(testData_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapt the label values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the sigmoid function (that we will be using later) returns a value between 0 and 1, we need to change the -1 labels to 0. In this way, we can consider that the values above or equal to the threshold 0.5 classify as 1, whereas the ones below that value are classified as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData_X[0]\n",
    "trainData_Y[trainData_Y==-1] = 0  # Change -1s to 0s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our test data has no labels, we can't check the accuracy of our network once it is trained. Thus, we divide our training dataset into 2 parts: train and validation. We decided that around 25% of the training data (70 cases) will be used for validation, and 75% for training (208 cases).\n",
    "\n",
    "The real test dataset will only be used to make predictions and send our results to the challenge waiting for a response of the accuracy of our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 64, 59)\n",
      "(70, 64, 59)\n",
      "(208, 1)\n",
      "(70, 1)\n"
     ]
    }
   ],
   "source": [
    "# We divide our training data in validation and train data\n",
    "train_trainData_X = trainData_X[:208]\n",
    "validation_trainData_X = trainData_X[208:]\n",
    "\n",
    "# We do the same for the labels\n",
    "train_trainData_Y = trainData_Y[:208]\n",
    "validation_trainData_Y = trainData_Y[208:]\n",
    "\n",
    "print(train_trainData_X.shape)\n",
    "print(validation_trainData_X.shape)\n",
    "\n",
    "print(train_trainData_Y.shape)\n",
    "print(validation_trainData_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series classification with RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first implementation we chose to use Recurrent Neural Networks. Apart from the recommendation of the description of the problem, we consider it an appropriate class of artificial neural network as several studies claim that RNNs are proven to perform better when analyzing data in a time series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We clear the default graph stack and reset the global default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Training Parameters\n",
    "learning_rate = 0.001 # How fast the weights update\n",
    "training_epochs = 208\n",
    "# For computational reasons, we will process data in mini-batches of size batch_size\n",
    "batch_size = 70 # Number of samples that will be propagated through the network\n",
    "total_batches = (train_trainData_X.shape[0]//batch_size) # Number of batches\n",
    "display_step = 200 # Show results every 'display' step\n",
    "\n",
    "# Network Parameters \n",
    "n_input = 64 # Number of inputs\n",
    "n_steps = 59 # Number of steps per input\n",
    "n_hidden = 64 # Hidden layer num of features\n",
    "# We will consider the number of classes is equal to 1, \n",
    "# therefore, we will be using the sigmoid function to determine whether a \n",
    "# case will be assigned label 0 or 1.\n",
    "n_classes = 1 \n",
    "\n",
    "\n",
    "alpha = 0.5 # Hyper-parameter of the combined loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input/Output placeholders for Tensorflow graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *placeholder* is simply a variable that we will assign data to at a later date. It allows us to create our operations and build our computation graph, without needing the data. In *TensorFlow* terminology, we then *feed* data into the graph through these placeholders.\n",
    "\n",
    "In this Recurrent Neural Network, our data is tridimensional. The first dimension of the placeholder is *None*, meaning we can have any number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, n_steps, n_input]) # shape: [batch_size, n_steps, n_inputs]\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "y_steps = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **weight_variable**: Helper function to create a weight variable initialized with a normal distribution.\n",
    "- **bias_variable**: Helper function to create a bias variable initialized with a constant value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.0, shape = shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM using Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first RNN uses Long short-term memory units, which are powerful and increasingly popular models for learning from sequence data. They effectively model varying length sequences and capture long range dependencies.\n",
    "- **LSTM**: Helper function to create the model architecture for LSTM units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM(x, weight, bias):\n",
    "    # We create a Long Short-Term Memory unit (LSTM) recurrent network cell\n",
    "    cell = rnn_cell.LSTMCell(n_hidden,state_is_tuple = True)\n",
    "    # RNN cell composed sequentially of multiple simple cells\n",
    "    multi_layer_cell = tf.nn.rnn_cell.MultiRNNCell([cell] * 2)\n",
    "    # We create a recurrent neural network specified by 'multi_layer_cell' and 'x' placeholder\n",
    "    output, state = tf.nn.dynamic_rnn(multi_layer_cell, x, dtype = tf.float32)\n",
    "    # We reshape the tensor (maintaining its value) with the special value -1 , in this way,\n",
    "    # the size of that dimension is computed so that the total size remains constant\n",
    "    output_flattened = tf.reshape(output, [-1, n_hidden])\n",
    "    # We multiply the tensor by the weight and add the bias\n",
    "    output_logits = tf.add(tf.matmul(output_flattened,weight),bias)\n",
    "    # We compute sigmoid of 'output_logits' element-wise. Specifically, y = 1 / (1 + exp(-x)).\n",
    "    output_all = tf.nn.sigmoid(output_logits)\n",
    "    # We reshape the output \n",
    "    output_reshaped = tf.reshape(output_all,[-1,n_steps,n_classes])\n",
    "    # Gather slices from the transpose of the reshaped output according to n_steps - 1.\n",
    "    output_last = tf.gather(tf.transpose(output_reshaped,[1,0,2]), n_steps - 1)\n",
    "    # We return the last step and all steps\n",
    "    return output_last, output_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:At least two cells provided to MultiRNNCell are the same object and will share weights.\n"
     ]
    }
   ],
   "source": [
    "weight = weight_variable([n_hidden,n_classes])\n",
    "bias = bias_variable([n_classes])\n",
    "y_last, y_all = LSTM(x,weight,bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function: binary cross entropy and target replication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function used in the paper is a combination of two losses \n",
    " - average loss of each time step prediction \n",
    " - loss of the prediction calculated at the last time step. Alpha in the combined loss function is a hyper-parameter. See this  [paper](https://arxiv.org/abs/1511.03677) for more information on target replication and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elsas.DESKTOP-DVRVL8F\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "all_steps_cost = -tf.reduce_mean((y_steps * tf.log(y_all))  + (1 - y_steps) * tf.log(1 - y_all))\n",
    "last_step_cost = -tf.reduce_mean((y * tf.log(y_last)) + ((1 - y) * tf.log(1 - y_last)))\n",
    "loss_function = (alpha * all_steps_cost) + ((1 - alpha) * last_step_cost)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the training and testing of the model we have gone through the epochs and total amount of batches. At first we wanted to loop through each of the examples ranged in the training data, as we consider it is a better practice. Nevertheless, as the results we were obtaining were out of range (NaN), the only way we were capable of obtaining some results was to decrease the number of training_epochs to 1 or 2, which resulted in the model giving us very poor results. For this reason, we have commented that line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score validation:  0.46568627450980393\n",
      "ROC AUC Score train:  0.6718027734976888\n",
      "ROC AUC Score validation:  0.4934640522875817\n",
      "ROC AUC Score train:  0.7575757575757576\n",
      "ROC AUC Score validation:  0.49101307189542487\n",
      "ROC AUC Score train:  0.84375\n",
      "ROC AUC Score validation:  0.5334967320261438\n",
      "ROC AUC Score train:  0.9024390243902439\n",
      "ROC AUC Score validation:  0.5318627450980392\n",
      "ROC AUC Score train:  0.9342105263157895\n",
      "ROC AUC Score validation:  0.5326797385620915\n",
      "ROC AUC Score train:  0.9230769230769231\n",
      "ROC AUC Score validation:  0.5024509803921569\n",
      "ROC AUC Score train:  0.9714285714285714\n",
      "ROC AUC Score validation:  0.5302287581699346\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5147058823529412\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47140522875817\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5\n",
      "ROC AUC Score train:  0.9852941176470588\n",
      "ROC AUC Score validation:  0.5130718954248366\n",
      "ROC AUC Score train:  0.9713349713349714\n",
      "ROC AUC Score validation:  0.4591503267973856\n",
      "ROC AUC Score train:  0.9852941176470588\n",
      "ROC AUC Score validation:  0.46895424836601307\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48774509803921573\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4436274509803922\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49836601307189543\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5024509803921569\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.548202614379085\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5874183006535947\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5563725490196079\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5155228758169935\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4738562091503268\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4722222222222222\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48692810457516333\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.41748366013071897\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4281045751633987\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4452614379084967\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4730392156862745\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4281045751633987\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4452614379084967\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4436274509803922\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4436274509803922\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4436274509803922\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.428921568627451\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4436274509803922\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4281045751633987\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4297385620915033\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.42728758169934644\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4436274509803922\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4550653594771241\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47140522875817\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4959150326797385\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.553921568627451\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5138888888888888\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5571895424836601\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5416666666666667\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.553921568627451\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5392156862745098\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5245098039215685\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5106209150326797\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4959150326797385\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5098039215686274\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5245098039215685\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.511437908496732\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5245098039215685\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5236928104575164\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48120915032679734\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49428104575163395\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.6004901960784315\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.6454248366013072\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.6601307189542484\n",
      "ROC AUC Score train:  0.9852941176470588\n",
      "ROC AUC Score validation:  0.6895424836601307\n",
      "ROC AUC Score train:  0.9852941176470588\n",
      "ROC AUC Score validation:  0.7181372549019608\n",
      "ROC AUC Score train:  0.9852941176470588\n",
      "ROC AUC Score validation:  0.6887254901960785\n",
      "ROC AUC Score train:  0.9852941176470588\n",
      "ROC AUC Score validation:  0.6601307189542484\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.6437908496732027\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.6143790849673203\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5996732026143792\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5996732026143792\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5710784313725491\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5710784313725491\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5710784313725491\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5710784313725491\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5433006535947712\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.542483660130719\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.542483660130719\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5563725490196079\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5563725490196079\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.542483660130719\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5563725490196079\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5710784313725491\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5563725490196079\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5269607843137255\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5285947712418301\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5294117647058824\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5155228758169935\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48611111111111116\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48611111111111116\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5147058823529412\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5285947712418301\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5147058823529412\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5147058823529412\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48529411764705876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48529411764705876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4558823529411765\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49918300653594766\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5130718954248366\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4844771241830065\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5130718954248366\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49918300653594766\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4697712418300653\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4844771241830065\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4419934640522876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47140522875817\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4697712418300653\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5130718954248366\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5416666666666667\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5555555555555556\n",
      "ROC AUC Score train:  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score validation:  0.49918300653594766\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5702614379084968\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5138888888888888\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5433006535947712\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5285947712418301\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5138888888888888\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5147058823529412\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5008169934640523\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5155228758169935\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48529411764705876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4575163398692811\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4575163398692811\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.41503267973856206\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.428921568627451\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.38725490196078427\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4011437908496732\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.40032679738562094\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.41503267973856206\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.3725490196078431\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4158496732026144\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4436274509803922\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4436274509803922\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4436274509803922\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4297385620915033\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4436274509803922\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4436274509803922\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4566993464052288\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.44281045751633985\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.44281045751633985\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.428921568627451\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.41503267973856206\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.41503267973856206\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4297385620915033\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.428921568627451\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4436274509803922\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47140522875817\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4436274509803922\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4575163398692811\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4575163398692811\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4575163398692811\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.44281045751633985\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.45833333333333337\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47140522875817\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48611111111111116\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4566993464052288\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4575163398692811\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.428921568627451\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4575163398692811\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.44281045751633985\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4575163398692811\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.44281045751633985\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47140522875817\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47140522875817\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.44281045751633985\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4575163398692811\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4722222222222222\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.44281045751633985\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4566993464052288\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4566993464052288\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47140522875817\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47140522875817\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48611111111111116\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48529411764705876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48611111111111116\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48529411764705876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48529411764705876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48529411764705876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4722222222222222\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48611111111111116\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5008169934640523\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5285947712418301\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48692810457516333\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5269607843137255\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5285947712418301\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49918300653594766\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.542483660130719\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.542483660130719\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5269607843137255\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5277777777777778\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5416666666666667\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5130718954248366\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5563725490196079\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5416666666666667\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5849673202614379\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5563725490196079\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5710784313725491\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.542483660130719\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5555555555555556\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5433006535947712\n",
      "ROC AUC Score train:  1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    # We initialize all trainable variables before training starts\n",
    "    tf.global_variables_initializer().run()\n",
    "    #for example in range(len(train_trainData_X)):\n",
    "    for epoch in range(training_epochs):\n",
    "        for b in range(int(total_batches)):   \n",
    "\n",
    "            # We obtain the \"offset\" added to each unit in the neural network layer\n",
    "            offset = (b * batch_size) % (train_trainData_Y.shape[0] - batch_size)\n",
    "            batch_x = np.reshape(train_trainData_X[offset:(offset + batch_size), :],[-1,59,64])\n",
    "            batch_y = train_trainData_Y[offset:(offset + batch_size), :]\n",
    "            batch_y_steps = np.tile(batch_y,(batch_x.shape[1],1))\n",
    "\n",
    "            reshaped_validation_trainData_X = np.reshape(validation_trainData_X,[-1,59,64])\n",
    "            _, c = session.run([optimizer, loss_function],feed_dict={x: batch_x, y : batch_y, y_steps: batch_y_steps})   \n",
    "        # Our predictions are numbers between 0 and 1, as we are using sigmoid function\n",
    "        pred_y_validation = session.run(y_last,feed_dict={x:reshaped_validation_trainData_X})\n",
    "        pred_y_train = session.run(y_last,feed_dict={x:batch_x})\n",
    "        # To obtain the predicted classes we consider of class 0 the values less than 0.5 \n",
    "        # and 1 the values equals or greater than 0.5\n",
    "        pred_y_validation[pred_y_validation<0.5]=0\n",
    "        pred_y_validation[pred_y_validation>=0.5]=1\n",
    "        pred_y_train[pred_y_train<0.5]=0\n",
    "        pred_y_train[pred_y_train>=0.5]=1\n",
    "        # After that, we compute the AUC score which provides an aggregate measure of performance \n",
    "        # across all possible classification thresholds.\n",
    "        print(\"ROC AUC Score validation: \",roc_auc_score(validation_trainData_Y,pred_y_validation))\n",
    "        print(\"ROC AUC Score train: \",roc_auc_score(pred_y_train,batch_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_validation=validation_trainData_Y\n",
    "\n",
    "# fpr means false-positive-rate\n",
    "# tpr means true-positive-rate\n",
    "fpr, tpr, _ = metrics.roc_curve(y_validation, pred_y_validation)\n",
    "auc_score = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.title('ROC Curve LSTM')\n",
    "plt.plot(fpr, tpr, label='AUC = {:.2f}'.format(auc_score))\n",
    "\n",
    "# We trace a diagonal to indicate where chance scores lie\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU using Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we implemented another approach by using Gated Recurrent Units as a gating mechanism for the reason that they have shown to exhibit better performance on smaller datasets. This a useful alternative to compare the results of both approaches.\n",
    "\n",
    "- **GRU**: Helper function to create the model architecture for GRU units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRU(x, weight, bias):\n",
    "    # We create a Gated Recurrent Unit cell\n",
    "    cell = rnn_cell.GRUCell(n_hidden)\n",
    "    # RNN cell composed sequentially of multiple simple cells\n",
    "    multi_layer_cell = tf.nn.rnn_cell.MultiRNNCell([cell] * 2)\n",
    "    # We create a recurrent neural network specified by 'multi_layer_cell' and 'x' placeholder\n",
    "    output, state = tf.nn.dynamic_rnn(multi_layer_cell, x, dtype = tf.float32)\n",
    "    # We reshape the tensor (maintaining its value) with the special value -1 , in this way,\n",
    "    # the size of that dimension is computed so that the total size remains constant\n",
    "    output_flattened = tf.reshape(output, [-1, n_hidden])\n",
    "    # We multiply the tensor by the weight and add the bias\n",
    "    output_logits = tf.add(tf.matmul(output_flattened,weight),bias)\n",
    "    # We compute sigmoid of 'output_logits' element-wise. Specifically, y = 1 / (1 + exp(-x)).\n",
    "    output_all = tf.nn.sigmoid(output_logits)\n",
    "    # We reshape the output \n",
    "    output_reshaped = tf.reshape(output_all,[-1,n_steps,n_classes])\n",
    "    # Gather slices from the transpose of the reshaped output according to n_steps - 1.\n",
    "    output_last = tf.gather(tf.transpose(output_reshaped,[1,0,2]), n_steps - 1)\n",
    "    # We return the last step and all steps\n",
    "    return output_last, output_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = weight_variable([n_hidden,n_classes])\n",
    "bias = bias_variable([n_classes])\n",
    "y_last, y_all = GRU(x,weight,bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function: binary cross entropy and target replication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have previously done for the LSTM, we compute the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elsas.DESKTOP-DVRVL8F\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "all_steps_cost = -tf.reduce_mean((y_steps * tf.log(y_all))  + (1 - y_steps) * tf.log(1 - y_all))\n",
    "last_step_cost = -tf.reduce_mean((y * tf.log(y_last)) + ((1 - y) * tf.log(1 - y_last)))\n",
    "loss_function = (alpha * all_steps_cost) + ((1 - alpha) * last_step_cost)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the process here is equal to the one in the previous cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score validation:  0.4297385620915033\n",
      "ROC AUC Score train:  0.5041666666666667\n",
      "ROC AUC Score validation:  0.4297385620915033\n",
      "ROC AUC Score train:  0.6175986842105263\n",
      "ROC AUC Score validation:  0.4297385620915033\n",
      "ROC AUC Score train:  0.7615131578947368\n",
      "ROC AUC Score validation:  0.4297385620915033\n",
      "ROC AUC Score train:  0.8429276315789473\n",
      "ROC AUC Score validation:  0.45996732026143794\n",
      "ROC AUC Score train:  0.8717105263157895\n",
      "ROC AUC Score validation:  0.4313725490196078\n",
      "ROC AUC Score train:  0.8995098039215685\n",
      "ROC AUC Score validation:  0.4313725490196078\n",
      "ROC AUC Score train:  0.9566993464052288\n",
      "ROC AUC Score validation:  0.41666666666666663\n",
      "ROC AUC Score train:  0.9713349713349714\n",
      "ROC AUC Score validation:  0.4444444444444444\n",
      "ROC AUC Score train:  0.9713349713349714\n",
      "ROC AUC Score validation:  0.48611111111111116\n",
      "ROC AUC Score train:  0.9713349713349714\n",
      "ROC AUC Score validation:  0.48529411764705876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49918300653594766\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49918300653594766\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5138888888888888\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5277777777777778\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5277777777777778\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5138888888888888\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4836601307189542\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5269607843137255\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49918300653594766\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5130718954248366\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5130718954248366\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49918300653594766\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5138888888888888\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5138888888888888\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5269607843137255\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5008169934640523\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5147058823529412\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49754901960784315\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5147058823529412\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49836601307189543\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49836601307189543\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5130718954248366\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49836601307189543\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5130718954248366\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5138888888888888\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5269607843137255\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5122549019607844\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5008169934640523\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5269607843137255\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5138888888888888\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5547385620915032\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5008169934640523\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.553921568627451\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48692810457516333\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5555555555555556\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5008169934640523\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5008169934640523\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5130718954248366\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5008169934640523\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5408496732026143\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5261437908496732\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5130718954248366\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.511437908496732\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5269607843137255\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49918300653594766\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5400326797385621\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5269607843137255\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5285947712418301\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5400326797385621\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5261437908496732\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5147058823529412\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5285947712418301\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49673202614379086\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49754901960784315\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49754901960784315\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49836601307189543\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49754901960784315\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49754901960784315\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49918300653594766\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.482843137254902\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4836601307189542\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4836601307189542\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4697712418300653\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4558823529411765\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4697712418300653\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4558823529411765\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4558823529411765\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4558823529411765\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4566993464052288\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4419934640522876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4697712418300653\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4566993464052288\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4419934640522876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49754901960784315\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4836601307189542\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4575163398692811\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4681372549019608\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49836601307189543\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5294117647058824\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49836601307189543\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.46895424836601307\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5008169934640523\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5008169934640523\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4697712418300653\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4844771241830065\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5147058823529412\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4558823529411765\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4558823529411765\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48529411764705876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4558823529411765\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4419934640522876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48611111111111116\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48529411764705876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48611111111111116\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48611111111111116\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48611111111111116\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48611111111111116\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48611111111111116\n",
      "ROC AUC Score train:  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score validation:  0.48611111111111116\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48529411764705876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48529411764705876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49918300653594766\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49918300653594766\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4844771241830065\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4844771241830065\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4844771241830065\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4844771241830065\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4844771241830065\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48529411764705876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4722222222222222\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4411764705882353\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49918300653594766\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48611111111111116\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48611111111111116\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49918300653594766\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49918300653594766\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49918300653594766\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49836601307189543\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48529411764705876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48529411764705876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49918300653594766\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4697712418300653\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4697712418300653\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4697712418300653\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4697712418300653\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4697712418300653\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4836601307189542\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4836601307189542\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49836601307189543\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4836601307189542\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4836601307189542\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49836601307189543\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4836601307189542\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49836601307189543\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4836601307189542\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49836601307189543\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4836601307189542\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49836601307189543\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4836601307189542\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.49836601307189543\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4836601307189542\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4836601307189542\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4836601307189542\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.46895424836601307\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4836601307189542\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4836601307189542\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.46895424836601307\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5122549019607844\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4844771241830065\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4566993464052288\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4697712418300653\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4844771241830065\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47140522875817\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4844771241830065\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.44281045751633985\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4697712418300653\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47140522875817\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4419934640522876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4558823529411765\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4558823529411765\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4558823529411765\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4558823529411765\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4558823529411765\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.4558823529411765\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.47058823529411764\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48529411764705876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48529411764705876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48529411764705876\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48611111111111116\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.48611111111111116\n",
      "ROC AUC Score train:  1.0\n",
      "ROC AUC Score validation:  0.5\n",
      "ROC AUC Score train:  1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    # We initialize all trainable variables before training starts\n",
    "    tf.global_variables_initializer().run()\n",
    "    #for example in range(len(train_trainData_X)):\n",
    "    for epoch in range(training_epochs):\n",
    "        for b in range(int(total_batches)):   \n",
    "\n",
    "            # We obtain the \"offset\" added to each unit in the neural network layer\n",
    "            offset = (b * batch_size) % (train_trainData_Y.shape[0] - batch_size)\n",
    "            batch_x = np.reshape(train_trainData_X[offset:(offset + batch_size), :],[-1,59,64])\n",
    "            batch_y = train_trainData_Y[offset:(offset + batch_size), :]\n",
    "            batch_y_steps = np.tile(batch_y,(batch_x.shape[1],1))\n",
    "\n",
    "            reshaped_validation_trainData_X = np.reshape(validation_trainData_X,[-1,59,64])\n",
    "            _, c = session.run([optimizer, loss_function],feed_dict={x: batch_x, y : batch_y, y_steps: batch_y_steps})   \n",
    "        # Our predictions are numbers between 0 and 1, as we are using sigmoid function\n",
    "        pred_y_validation = session.run(y_last,feed_dict={x:reshaped_validation_trainData_X})\n",
    "        pred_y_train = session.run(y_last,feed_dict={x:batch_x})\n",
    "        # To obtain the predicted classes we consider of class 0 the values less than 0.5 \n",
    "        # and 1 the values equals or greater than 0.5\n",
    "        pred_y_validation[pred_y_validation<0.5]=0\n",
    "        pred_y_validation[pred_y_validation>=0.5]=1\n",
    "        pred_y_train[pred_y_train<0.5]=0\n",
    "        pred_y_train[pred_y_train>=0.5]=1\n",
    "        # After that, we compute the AUC score which provides an aggregate measure of performance \n",
    "        # across all possible classification thresholds.\n",
    "        print(\"ROC AUC Score validation: \",roc_auc_score(validation_trainData_Y,pred_y_validation))\n",
    "        print(\"ROC AUC Score train: \",roc_auc_score(pred_y_train,batch_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_validation=validation_trainData_Y\n",
    "\n",
    "# fpr means false-positive-rate\n",
    "# tpr means true-positive-rate\n",
    "fpr, tpr, _ = metrics.roc_curve(y_validation, pred_y_validation)\n",
    "auc_score = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.title('ROC Curve GRU')\n",
    "plt.plot(fpr, tpr, label='AUC = {:.2f}'.format(auc_score))\n",
    "\n",
    "# We trace a diagonal to indicate where chance scores lie\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN using Keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benefit of using CNNs for sequence classification is that they can learn from the raw time series data directly, and in turn do not require domain expertise to manually engineer input features. The model can learn an internal representation of the time series data and ideally achieve comparable performance to models fit on a version of the dataset with engineered features.\n",
    "\n",
    "In this approach we decided to use Keras as an alternative to Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we must define the CNN model using the Keras deep learning library. The model requires a three-dimensional input with [samples, time steps, features]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These input and output dimensions are required when fitting the model\n",
    "n_timesteps, n_features, n_outputs = 59, 64 , 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined the model as having two 1D CNN layers, followed by a dropout layer for regularization and then a pooling layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, validationX, validationy):\n",
    "    verbose, epochs, batch_size = 0, 208, 70\n",
    "    model = Sequential()\n",
    "    # It is common to define CNN layers in groups of two in order to give the model\n",
    "    # a good chance of learning features from the input data\n",
    "    # For this model, we have used a standard configuration of 64 parallel feature maps and a kernel size of 3. \n",
    "    # The feature maps are the number of times the input is processed or interpreted,\n",
    "    # whereas the kernel size is the number of input time steps considered as the input sequence\n",
    "    # is read or processed onto the feature maps\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_features,n_timesteps)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    # CNNs learn very quickly, therefore, the dropout layer is intended to help slow down \n",
    "    # the learning process and hopefully result in a better final model\n",
    "    model.add(Dropout(0.5))\n",
    "    # The pooling layer reduces the learned features to 1/4 their size, \n",
    "    # consolidating them to only the most essential elements\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    # After the CNN and pooling, the learned features are flattened to one long vector\n",
    "    # and pass through a fully connected layer before the output layer used to make a prediction\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    # In this case as we have set the number of classes equals 2, we could not use the sigmoid\n",
    "    # function, instead, we have used softmax\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    # The efficient Adam version of stochastic gradient descent will be used to optimize the network,\n",
    "    # moreover, as the labels are integers, we are using sparse_categorical_crossentropy\n",
    "    # instead of categorical_crossentropy\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    preds = model.predict(trainX,batch_size=batch_size,verbose=verbose,steps=None)\n",
    "    # evaluate model\n",
    "    # Once the model is fit, it is evaluated on the validation dataset \n",
    "    # and the accuracy of the fit model on the validation dataset is returned.\n",
    "    _, accuracy = model.evaluate(validationX, validationy, batch_size=batch_size, verbose=0)\n",
    "    return preds, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider that the skill of the model can't be judged from a single evaluation.\n",
    "The reason for this consideration is that neural networks are stochastic, meaning that a different specific model will result when training the same model configuration on the same data.\n",
    "This feature of the network gives the model its adaptive ability, but also for this reason it requires a slightly more complicated evaluation of the model.\n",
    "\n",
    "We will repeat the evaluation of the model multiple times, then summarize the performance of the model across each of those runs. In conclusion, we can call evaluate_model() a total of 10 times, which will result in a population of model evaluation scores that must be summarized.\n",
    "\n",
    "We can summarize the sample of scores by calculating and reporting the mean and standard deviation of the performance. The mean gives the average accuracy of the model on the dataset, whereas the standard deviation gives the average variance of the accuracy from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize scores\n",
    "# The function summarize_results() below summarizes the results of a run\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can bundle up the repeated evaluation, gathering of results, and summarization of results into a main function, called run_experiment()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run an experiment\n",
    "# By default, the model is evaluated 10 times before the performance of the model is reported.\n",
    "def run_experiment(repeats=10):\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        preds, score = evaluate_model(train_trainData_X, train_trainData_Y, validation_trainData_X, validation_trainData_Y)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_results(scores)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">#1: 48.571\n",
      ">#2: 51.429\n",
      ">#3: 51.429\n",
      ">#4: 67.143\n",
      ">#5: 72.857\n",
      ">#6: 70.000\n",
      ">#7: 48.571\n",
      ">#8: 78.571\n",
      ">#9: 51.429\n",
      ">#10: 77.143\n",
      "[48.571428656578064, 51.428574323654175, 51.428574323654175, 67.14285612106323, 72.85714149475098, 69.9999988079071, 48.571428656578064, 78.57142686843872, 51.428574323654175, 77.14285850524902]\n",
      "Accuracy: 61.714% (+/-11.863)\n"
     ]
    }
   ],
   "source": [
    "# run the experiment\n",
    "preds = run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN (LSTM vs. GRU)**\n",
    "\n",
    "Analysing the results obtained from the LSTM and GRU executions, we can observe that they result in  similar ROC AUC scores. The performance of GRU is on par with LSTM, but it is computationally more efficient, because it lacks of memory unit and therefore has a less complex structure.\n",
    "\n",
    "We can also see that ROC AUC scores have some peak values where it reaches a higher score and after that starts to decrease. From our point of view, in order to get most from the model an early stop should be applied when a peak is detected to ensure we end up with the model that gives us the best results.\n",
    "\n",
    "**CNN**\n",
    "\n",
    "We have observed that when the model gives us an accuracy of 48.571 or 51.429\n",
    "is because the model has predicted that all the labels are from class 0 or class 1.\n",
    "\n",
    "The overall accuracy is pretty decent. Nevertheless, as we have repeated the execution several times we should choose as our final model the one that has reached a higher accuracy value from the total amount of experiments.\n",
    "\n",
    "**Comparison with the contest results**\n",
    "\n",
    "As it can be observed in the contest [results](http://www.bbci.de/competition/iii/results/) for the Data set I [Tübingen], almost no one used neural networks to solve the problem, therefore, we consider ours was a pretty innovative approach. In comparison to the results of the contestant teams, we can see that we are above the mean of accuracy obtained by other contestants, taking as our final model the one that has reached a higher accuracy value from the total amount of experiments executed on the CNN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
